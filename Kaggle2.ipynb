{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{},"source":["This is an example notebook for testing noise filtering methods on Birds Dataset.\n","The focus is to start to explore some techniques of preprocessing that can be used to improve bird detection models.\n","The problem is that the Cornell Birdcall Identification Dataset have many sounds of low quality, with high level background sounds and noises. Thus, I believe that applying some filtering method for noise reduction can improve the classification task.\n","\n","Common detection pipelines consist of:\n","* Preprocessing: To read a audio file, optionally apply signal filtering techniques, and perform feature extraction (e.g. mfccs);\n","* Trainning a classification model based on features (TO DO);\n","* Evaluation: To test the trainned models over a split of the dataset (TO DO).\n","\n","The preprocess methods you can see here are:\n","* Traditional log mel-spectogram;\n","* High-Pass Filtering: Reduces low frequencies, once bird sound are commonly present on high frequencies;\n","* Per-channel energy normalization (PCEN): Technique for automatic gain control, followed by nonlinear compression;\n","* Spectral Gating: Common strategy for denoising music by gating the signal only on high level sounds.\n","\n","Please, use this notebook as a didactical one. \n","If you enjoy it, please, leave your upvote and comments.\n","\n","Thanks!"]},{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting librosa\n","  Obtaining dependency information for librosa from https://files.pythonhosted.org/packages/e2/a2/4f639c1168d7aada749a896afb4892a831e2041bebdcf636aebfe9e86556/librosa-0.10.1-py3-none-any.whl.metadata\n","  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n","Collecting audioread>=2.1.9 (from librosa)\n","  Obtaining dependency information for audioread>=2.1.9 from https://files.pythonhosted.org/packages/57/8d/30aa32745af16af0a9a650115fbe81bde7c610ed5c21b381fca0196f3a7f/audioread-3.0.1-py3-none-any.whl.metadata\n","  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa) (1.24.2)\n","Requirement already satisfied: scipy>=1.2.0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa) (1.10.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa) (1.3.1)\n","Requirement already satisfied: joblib>=0.14 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa) (1.2.0)\n","Requirement already satisfied: decorator>=4.3.0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa) (5.1.1)\n","Requirement already satisfied: numba>=0.51.0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa) (0.58.1)\n","Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa) (0.12.1)\n","Collecting pooch>=1.0 (from librosa)\n","  Obtaining dependency information for pooch>=1.0 from https://files.pythonhosted.org/packages/1a/a5/5174dac3957ac412e80a00f30b6507031fcab7000afc9ea0ac413bddcff2/pooch-1.8.0-py3-none-any.whl.metadata\n","  Downloading pooch-1.8.0-py3-none-any.whl.metadata (9.9 kB)\n","Collecting soxr>=0.3.2 (from librosa)\n","  Obtaining dependency information for soxr>=0.3.2 from https://files.pythonhosted.org/packages/3c/e7/89951b917600d02f7389e760696c32b70a80a96301d0a018a70a317e4ecc/soxr-0.3.7-cp310-cp310-win_amd64.whl.metadata\n","  Downloading soxr-0.3.7-cp310-cp310-win_amd64.whl.metadata (5.7 kB)\n","Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa) (4.5.0)\n","Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa) (0.3)\n","Collecting msgpack>=1.0 (from librosa)\n","  Obtaining dependency information for msgpack>=1.0 from https://files.pythonhosted.org/packages/4b/14/c62fbc8dff118f1558e43b9469d56a1f37bbb35febadc3163efaedd01500/msgpack-1.0.7-cp310-cp310-win_amd64.whl.metadata\n","  Downloading msgpack-1.0.7-cp310-cp310-win_amd64.whl.metadata (9.4 kB)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from numba>=0.51.0->librosa) (0.41.1)\n","Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pooch>=1.0->librosa) (3.11.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pooch>=1.0->librosa) (23.0)\n","Requirement already satisfied: requests>=2.19.0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pooch>=1.0->librosa) (2.28.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n","Requirement already satisfied: cffi>=1.0 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n","Requirement already satisfied: pycparser in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\33647\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n","Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n","   ---------------------------------------- 0.0/253.7 kB ? eta -:--:--\n","   - -------------------------------------- 10.2/253.7 kB ? eta -:--:--\n","   ------ -------------------------------- 41.0/253.7 kB 653.6 kB/s eta 0:00:01\n","   -------------- ------------------------ 92.2/253.7 kB 751.6 kB/s eta 0:00:01\n","   ------------------ ------------------- 122.9/253.7 kB 722.1 kB/s eta 0:00:01\n","   -------------------------- ----------- 174.1/253.7 kB 751.6 kB/s eta 0:00:01\n","   --------------------------------- ---- 225.3/253.7 kB 811.5 kB/s eta 0:00:01\n","   -------------------------------------- 253.7/253.7 kB 780.4 kB/s eta 0:00:00\n","Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n","Downloading msgpack-1.0.7-cp310-cp310-win_amd64.whl (222 kB)\n","   ---------------------------------------- 0.0/222.8 kB ? eta -:--:--\n","   ----- ---------------------------------- 30.7/222.8 kB 1.4 MB/s eta 0:00:01\n","   ------------ -------------------------- 71.7/222.8 kB 787.7 kB/s eta 0:00:01\n","   ------------------------- -------------- 143.4/222.8 kB 1.1 MB/s eta 0:00:01\n","   ---------------------------------- ----- 194.6/222.8 kB 1.1 MB/s eta 0:00:01\n","   ---------------------------------------- 222.8/222.8 kB 1.0 MB/s eta 0:00:00\n","Downloading pooch-1.8.0-py3-none-any.whl (62 kB)\n","   ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n","   -------------------------- ------------- 41.0/62.7 kB 991.0 kB/s eta 0:00:01\n","   ---------------------------------------- 62.7/62.7 kB 1.1 MB/s eta 0:00:00\n","Downloading soxr-0.3.7-cp310-cp310-win_amd64.whl (184 kB)\n","   ---------------------------------------- 0.0/184.6 kB ? eta -:--:--\n","   ------------- -------------------------- 61.4/184.6 kB 1.6 MB/s eta 0:00:01\n","   -------------------------- ------------- 122.9/184.6 kB 1.4 MB/s eta 0:00:01\n","   ---------------------------------------- 184.6/184.6 kB 1.4 MB/s eta 0:00:00\n","Installing collected packages: soxr, msgpack, audioread, pooch, librosa\n","Successfully installed audioread-3.0.1 librosa-0.10.1 msgpack-1.0.7 pooch-1.8.0 soxr-0.3.7\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n","[notice] To update, run: C:\\Users\\33647\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install librosa"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["# feature extractoring and preprocessing data\n","import librosa\n","import librosa.display\n","import pandas as pd\n","import numpy as np\n","import scipy.signal\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from PIL import Image\n","from pathlib import Path\n","from pylab import rcParams\n","rcParams['figure.figsize'] = 14, 6\n","\n","import csv\n","# Preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","#Reports\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing methods"]},{"cell_type":"markdown","metadata":{},"source":["## Reading some audio samples"]},{"cell_type":"markdown","metadata":{},"source":["Let's see some preprocessing techniques over the example_test_audio dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sr = 16000\n","e_file1 = '../input/birdsong-recognition/example_test_audio/BLKFR-10-CPL_20190611_093000.pt540.mp3'\n","e_file2 = '../input/birdsong-recognition/example_test_audio/ORANGE-7-CAP_20190606_093000.pt623.mp3'\n","\n","# 10 seconds of each file\n","y1,sr = librosa.load(e_file1, mono=True, sr=sr, offset=0, duration=10)\n","y2,sr = librosa.load(e_file2, mono=True, sr=sr, offset=0, duration=10)"]},{"cell_type":"markdown","metadata":{},"source":["Listen to them!"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from IPython.display import Audio, IFrame, display\n","\n","display(Audio(y1,rate=sr))\n","display(Audio(y2,rate=sr))"]},{"cell_type":"markdown","metadata":{},"source":["As you can hear, the first audio presents a high level background noise, and birds seems far from the mic. In the second audio, bird sounds are much more distinguished from the other noises. We can say that the second audio presents a better SNR (signal-noise ratio)."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.waveplot(y1,sr=sr, x_axis='time');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.waveplot(y2,sr=sr, x_axis='time');"]},{"cell_type":"markdown","metadata":{},"source":["If you look to both signal waves, you can see that the first sound presents a lower difference between the background level and some sound events, while this difference is much higher in the second sound. If you do it in sync with the audio, we can see that some bird calls does not appear from the average sound level."]},{"cell_type":"markdown","metadata":{},"source":["## Logmel-spectogram"]},{"cell_type":"markdown","metadata":{},"source":["A very common preprocessing technique in audio detection applications is to transform audios to its log mel-spectogram representation.\n","Some concepts here: https://en.wikipedia.org/wiki/Mel-frequency_cepstrum"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["S1 = librosa.feature.melspectrogram(y=y1, sr=sr, n_mels=64)\n","D1 = librosa.power_to_db(S1, ref=np.max)\n","librosa.display.specshow(D1, x_axis='time', y_axis='mel');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["S2 = librosa.feature.melspectrogram(y=y2, sr=sr, n_mels=64)\n","D2 = librosa.power_to_db(S2, ref=np.max)\n","librosa.display.specshow(D2, x_axis='time', y_axis='mel');"]},{"cell_type":"markdown","metadata":{},"source":["The differences become very clear in the log mel spectogram. In the fist case, you can see a lot of artefacts on low frequencies (not birds), and the birds are in levels below the background noises. Besides, background noises are higher in frequencies below 2 kHz."]},{"cell_type":"markdown","metadata":{},"source":["## Filtering low-frequencies"]},{"cell_type":"markdown","metadata":{},"source":["As we noticed, low frequencies does not contribute to bird sounds, a first idea is to remove these low frequencies. A high pass filter helps in this task. Reference: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.lfilter.html"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from scipy import signal\n","import random\n","\n","\n","def f_high(y,sr):\n","    b,a = signal.butter(10, 2000/(sr/2), btype='highpass')\n","    yf = signal.lfilter(b,a,y)\n","    return yf\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["yf1 = f_high(y1, sr)\n","yf2 = f_high(y2, sr)"]},{"cell_type":"markdown","metadata":{},"source":["Let's see..."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.waveplot(y1,sr=sr, x_axis='time');\n","librosa.display.waveplot(yf1,sr=sr, x_axis='time');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.waveplot(y2,sr=sr, x_axis='time');\n","librosa.display.waveplot(yf2,sr=sr, x_axis='time');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Sf1 = librosa.feature.melspectrogram(y=yf1, sr=sr, n_mels=64)\n","Df1 = librosa.power_to_db(Sf1, ref=np.max)\n","librosa.display.specshow(Df1, x_axis='time', y_axis='mel');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Sf2 = librosa.feature.melspectrogram(y=yf2, sr=sr, n_mels=64)\n","Df2 = librosa.power_to_db(Sf2, ref=np.max)\n","librosa.display.specshow(Df2, x_axis='time', y_axis='mel');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["display(Audio(yf1,rate=sr))\n","display(Audio(yf2,rate=sr))"]},{"cell_type":"markdown","metadata":{},"source":["In both cases, the filter helped to isolate the interesting frequencies. The second audio is in a very good quality for distincting the birds. But the first audio also have high level noises in bird frequencies. Simply removing these frequencies can make us loose important information."]},{"cell_type":"markdown","metadata":{},"source":["## PCEN"]},{"cell_type":"markdown","metadata":{},"source":["PCEN has become a very useful strategy for acoustic event detection, and it has shown to perform better in such tasks as a frontend. Its idea is to perform non-linear compression on time-frequency channels.\n","\n","I am using the example shown here: https://librosa.org/doc/latest/generated/librosa.pcen.html?highlight=pcen#librosa.pcen"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Dp1 = librosa.pcen(S1 * (2**31), sr=sr, gain=1.1, hop_length=512, bias=2, power=0.5, time_constant=0.8, eps=1e-06, max_size=2)\n","Dp2 = librosa.pcen(S2 * (2**31), sr=sr, gain=1.1, hop_length=512, bias=2, power=0.5, time_constant=0.8, eps=1e-06, max_size=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.specshow(Dp1, x_axis='time', y_axis='mel');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.specshow(Dp2, x_axis='time', y_axis='mel');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["yp1 = librosa.feature.inverse.mel_to_audio(Dp1)\n","yp2 = librosa.feature.inverse.mel_to_audio(Dp2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.waveplot(yp1,sr=sr, x_axis='time');\n","librosa.display.waveplot(y1,sr=sr, x_axis='time');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.waveplot(yp2,sr=sr, x_axis='time');\n","librosa.display.waveplot(y2,sr=sr, x_axis='time');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["display(Audio(yp1,rate=sr))\n","display(Audio(yp2,rate=sr))"]},{"cell_type":"markdown","metadata":{},"source":["Uowwwww! It looks very promising!\n","This method does not eliminate all background, but the bird signal shapes are much more visible in the spectograms.\n","This method works on time-frequency representarions of the sounds, so I perform signal reconstitution from spectogram to audio to gives us a good idea on how it worked. This recostitution is not perfect, some artefacts are inserted."]},{"cell_type":"markdown","metadata":{},"source":["## Spectral Gating"]},{"cell_type":"markdown","metadata":{},"source":["This is also a technique for noise reduction based on gates that monitor audio level. It is commonly used in music industry, and present in tools like Audacity (https://wiki.audacityteam.org/wiki/How_Audacity_Noise_Reduction_Works).\n","I reproduced here the code made available by Tim Sainburg in his github (https://github.com/timsainb/noisereduce)."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import time\n","from datetime import timedelta as td\n","\n","\n","def _stft(y, n_fft, hop_length, win_length):\n","    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n","\n","\n","def _istft(y, hop_length, win_length):\n","    return librosa.istft(y, hop_length, win_length)\n","\n","\n","def _amp_to_db(x):\n","    return librosa.core.amplitude_to_db(x, ref=1.0, amin=1e-20, top_db=80.0)\n","\n","\n","def _db_to_amp(x,):\n","    return librosa.core.db_to_amplitude(x, ref=1.0)\n","\n","\n","def plot_spectrogram(signal, title):\n","    fig, ax = plt.subplots(figsize=(20, 4))\n","    cax = ax.matshow(\n","        signal,\n","        origin=\"lower\",\n","        aspect=\"auto\",\n","        cmap=plt.cm.seismic,\n","        vmin=-1 * np.max(np.abs(signal)),\n","        vmax=np.max(np.abs(signal)),\n","    )\n","    fig.colorbar(cax)\n","    ax.set_title(title)\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def plot_statistics_and_filter(\n","    mean_freq_noise, std_freq_noise, noise_thresh, smoothing_filter\n","):\n","    fig, ax = plt.subplots(ncols=2, figsize=(20, 4))\n","    plt_mean, = ax[0].plot(mean_freq_noise, label=\"Mean power of noise\")\n","    plt_std, = ax[0].plot(std_freq_noise, label=\"Std. power of noise\")\n","    plt_std, = ax[0].plot(noise_thresh, label=\"Noise threshold (by frequency)\")\n","    ax[0].set_title(\"Threshold for mask\")\n","    ax[0].legend()\n","    cax = ax[1].matshow(smoothing_filter, origin=\"lower\")\n","    fig.colorbar(cax)\n","    ax[1].set_title(\"Filter for smoothing Mask\")\n","    plt.show()\n","\n","def removeNoise(\n","    audio_clip,\n","    noise_clip,\n","    n_grad_freq=2,\n","    n_grad_time=4,\n","    n_fft=2048,\n","    win_length=2048,\n","    hop_length=512,\n","    n_std_thresh=1.5,\n","    prop_decrease=1.0,\n","    verbose=False,\n","    visual=False,\n","):\n","    \"\"\"Remove noise from audio based upon a clip containing only noise\n","\n","    Args:\n","        audio_clip (array): The first parameter.\n","        noise_clip (array): The second parameter.\n","        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n","        n_grad_time (int): how many time channels to smooth over with the mask.\n","        n_fft (int): number audio of frames between STFT columns.\n","        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n","        hop_length (int):number audio of frames between STFT columns.\n","        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n","        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n","        visual (bool): Whether to plot the steps of the algorithm\n","\n","    Returns:\n","        array: The recovered signal with noise subtracted\n","\n","    \"\"\"\n","    if verbose:\n","        start = time.time()\n","    # STFT over noise\n","    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n","    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # convert to dB\n","    # Calculate statistics over noise\n","    mean_freq_noise = np.mean(noise_stft_db, axis=1)\n","    std_freq_noise = np.std(noise_stft_db, axis=1)\n","    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n","    if verbose:\n","        print(\"STFT on noise:\", td(seconds=time.time() - start))\n","        start = time.time()\n","    # STFT over signal\n","    if verbose:\n","        start = time.time()\n","    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n","    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n","    if verbose:\n","        print(\"STFT on signal:\", td(seconds=time.time() - start))\n","        start = time.time()\n","    # Calculate value to mask dB to\n","    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n","    #print(noise_thresh, mask_gain_dB)\n","    # Create a smoothing filter for the mask in time and frequency\n","    smoothing_filter = np.outer(\n","        np.concatenate(\n","            [\n","                np.linspace(0, 1, n_grad_freq + 1, endpoint=False),\n","                np.linspace(1, 0, n_grad_freq + 2),\n","            ]\n","        )[1:-1],\n","        np.concatenate(\n","            [\n","                np.linspace(0, 1, n_grad_time + 1, endpoint=False),\n","                np.linspace(1, 0, n_grad_time + 2),\n","            ]\n","        )[1:-1],\n","    )\n","    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n","    # calculate the threshold for each frequency/time bin\n","    db_thresh = np.repeat(\n","        np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n","        np.shape(sig_stft_db)[1],\n","        axis=0,\n","    ).T\n","    # mask if the signal is above the threshold\n","    sig_mask = sig_stft_db < db_thresh\n","    if verbose:\n","        print(\"Masking:\", td(seconds=time.time() - start))\n","        start = time.time()\n","    # convolve the mask with a smoothing filter\n","    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n","    sig_mask = sig_mask * prop_decrease\n","    if verbose:\n","        print(\"Mask convolution:\", td(seconds=time.time() - start))\n","        start = time.time()\n","    # mask the signal\n","    sig_stft_db_masked = (\n","        sig_stft_db * (1 - sig_mask)\n","        + np.ones(np.shape(mask_gain_dB)) * mask_gain_dB * sig_mask\n","    )  # mask real\n","    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n","    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (\n","        1j * sig_imag_masked\n","    )\n","    if verbose:\n","        print(\"Mask application:\", td(seconds=time.time() - start))\n","        start = time.time()\n","    # recover the signal\n","    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n","    recovered_spec = _amp_to_db(\n","        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n","    )\n","    if verbose:\n","        print(\"Signal recovery:\", td(seconds=time.time() - start))\n","    if visual:\n","        plot_spectrogram(noise_stft_db, title=\"Noise\")\n","    if visual:\n","        plot_statistics_and_filter(\n","            mean_freq_noise, std_freq_noise, noise_thresh, smoothing_filter\n","        )\n","    if visual:\n","        plot_spectrogram(sig_stft_db, title=\"Signal\")\n","    if visual:\n","        plot_spectrogram(sig_mask, title=\"Mask applied\")\n","    if visual:\n","        plot_spectrogram(sig_stft_db_masked, title=\"Masked signal\")\n","    if visual:\n","        plot_spectrogram(recovered_spec, title=\"Recovered spectrogram\")\n","    return recovered_signal"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["noise1 = y1[5*sr:6*sr]\n","yg1 = removeNoise(audio_clip=y1, noise_clip=noise1,\n","    n_grad_freq=2,\n","    n_grad_time=4,\n","    n_fft=2048,\n","    win_length=2048,\n","    hop_length=512,\n","    n_std_thresh=1.5,\n","    prop_decrease=1.0,\n","    verbose=False,\n","    visual=False)\n","noise2 = y2[0:1*sr]\n","yg2 = removeNoise(audio_clip=y2, noise_clip=noise2,\n","    n_grad_freq=2,\n","    n_grad_time=4,\n","    n_fft=2048,\n","    win_length=2048,\n","    hop_length=512,\n","    n_std_thresh=2.5,\n","    prop_decrease=1.0,\n","    verbose=False,\n","    visual=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.waveplot(y1,sr=sr, x_axis='time');\n","librosa.display.waveplot(yg1,sr=sr, x_axis='time');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["librosa.display.waveplot(y2,sr=sr, x_axis='time');\n","librosa.display.waveplot(yg2,sr=sr, x_axis='time');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Sg1 = librosa.feature.melspectrogram(y=yg1, sr=sr, n_mels=64)\n","Dg1 = librosa.power_to_db(Sg1, ref=np.max)\n","librosa.display.specshow(Dg1, x_axis='time', y_axis='mel');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Sg2 = librosa.feature.melspectrogram(y=yg2, sr=sr, n_mels=64)\n","Dg2 = librosa.power_to_db(Sg2, ref=np.max)\n","librosa.display.specshow(Dg2, x_axis='time', y_axis='mel');"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["display(Audio(yg1,rate=sr))\n","display(Audio(yg2,rate=sr))"]},{"cell_type":"markdown","metadata":{},"source":["It didn't work so well on the noisy sound, but it was very good on the high SNR sample. Maybe some parameters can be adjusted to improve the results."]},{"cell_type":"markdown","metadata":{},"source":["# Combining the methods"]},{"cell_type":"markdown","metadata":{},"source":["Yes, I know what you are thinking. What if I combine these methods? From this code it is very easy to do such tests.\n","\n","Also, there are lots of parameter to try!\n","\n","It is up to you."]},{"cell_type":"markdown","metadata":{},"source":["# Impact on training and classification"]},{"cell_type":"markdown","metadata":{},"source":["I am still testing these preprocessing methods on my models.\n","\n","By now, I have a very initial model here: https://www.kaggle.com/mauriciofigueiredo/intro-to-filtering-process-model-submitting\n","\n","As you can see, it is a very basic model based on KNN over mfcc features. I combined some of the above strategies and applied on a subset of bird classes. The accuracy increase was around 10% over a split of  the selected data."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":1292430,"sourceId":19596,"sourceType":"competition"}],"dockerImageVersionId":29962,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
